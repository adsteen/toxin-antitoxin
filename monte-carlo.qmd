---
title: "Monte Carlo analysis of test statistic distributions"
#format: html
format: gfm
editor: visual
cache: true
---

# Introduction

The previous analysis ([normality_analysis.md](normality_analysis.md)) showed that parametric ANOVA is inappropriate for these datasets, because they're pretty badly unbalanced and because they're pretty badly heteroskedastic.  

Here I'm taking a resampling/Monte Carlo approach, in which I repeatedly, randomly shuffle the labels on our data set, thus creating a data set for which the null hypothesis (no significant differences among treatments) is known to be true. Comparing the distribution of test statistics (the t value) under the null hypothesis to the observed test statistic. If the observed t statistic is more extreme than (1-$\alpha$; typically 95\%) of the test statistics under the null hypothesis, we would call the result statistically significant.

# zor-orz

We'll start with the full analysis for zor-orz. 

```{r setup, message=FALSE, echo=TRUE}
library(tidyverse)
library(MASS)
library(furrr) # purrr for parallel processes
library(tictoc)
library(rlang) # this is maybe needed by calculate_mean_diff
plan(multisession) # seems like multicore is way faster but I'm working in RStudio which doesn't support multicore
source("helper_funs.R")

theme_set(theme_classic()) # set the graphical theme
```

Load the data, which are grouped counts but need to be recast as original observations. 

```{r read_raw_data, echo=TRUE}
# Load data - 
# Read in raw zor-orz data
region_zor <- readxl::read_xlsx("data/FINAL data for Steen.xlsx", 
                            sheet = "zor-orz gene number",
                            range = "A11:G18") %>%
  rename(gene.count = Continent) %>%
  pivot_longer(-1, names_to = "category", values_to = "count") %>%
  group_by(category) %>%
  mutate(freq = count / sum(count, na.rm = TRUE))
  
path_zor <- readxl::read_xlsx("data/FINAL data for Steen.xlsx", 
                            sheet = "zor-orz gene number",
                            range = "A1:E8") %>%
  rename(gene.count = Pathotype) %>%
  pivot_longer(-1, names_to = "category", values_to = "count") %>%
  group_by(category) %>%
  mutate(freq = count / sum(count, na.rm = TRUE))

# recreate raw data based on frequencies of gene abundance
raw_region_zor <- recreate_raw(region_zor) %>%
  arrange(category) # this appears to have worked
raw_path_zor <- recreate_raw(path_zor)

```

# Monte Carlo simulations

Based on the results of the `normality_analysis.qmd` workbook, it is inappropriate to assume that f-values are distributed according to the f-distribution.

So first we'll determine the distribution of f values under the null hypothesis. We do 10,000 simulations, which (as we'll see) is plenty to get a smooth distribution and to get a reasonably precise idea of where the 5\% cutoff lies.

```{r monte_carlo}
# Set the number of monte carlo replicates
n <- 10000

#tic()
reg.f.vec <- 1:n |> 
  future_map_dbl(.f = shuf_calc_f,
                 df = raw_region_zor,
                 .options = furrr_options(seed = 2112)) # great, if you're *really* into prog rock
path.f.vec <- 1:n |> 
  future_map_dbl(.f = shuf_calc_f,
                 df = raw_path_zor,
                 .options = furrr_options(seed = 444)) # aesthetically pleasing, dontcha think?
#toc() # Runs in about 12 seconds on 8 core macbook pro
#... or about 6 seconds with multicore, but that's not an option

# put the simulated f values in a data frame
f_vals <- data.frame(reg.sim.f = reg.f.vec,
                     path.sim.f = path.f.vec)
```
Now we measure the two actual f values:
```{r get_actual_f}
# Pull out actual f values
region_model <- lm(gene.count ~ category, data = raw_region_zor)
reg.f.real <- summary(aov(region_model))[[1]][1,4] # 9.335
path_model <- lm(gene.count ~ category, data = raw_path_zor)
path.f.real <- summary(aov(path_model))[[1]][1,4] # 46.035
```


How do the real f values compare to the simulated, null-hypothesis values?

```{r plot_by_regions}
p_reg_hist <- ggplot(f_vals, aes(x=reg.sim.f)) + 
  geom_histogram(bins = 100) + 
  geom_vline(xintercept = reg.f.real, color="red")  + 
  ggtitle("data by region")
print(p_reg_hist)
```

```{r plot_by_pathology}
p_path_hist <- ggplot(f_vals, aes(x=path.sim.f)) + 
  geom_histogram(bins = 100) + 
  geom_vline(xintercept = path.f.real, color="red") + 
  ggtitle("data by pathology")
print(p_path_hist)
```

So: I have simulated `r format(n, scientific=FALSE, big.mark=",")` and found that, for each case, the actual measured *f* values are much, much larger than they would be likely to be if the null hypothesis were true - so much larger that we can't calculate a p value, because none of our `r format(n, scientific=FALSE, big.mark=",")` simulations captured a *f* value that big. We can say conservatively say that, in each case, p \< `r 1/n`.

In summary:

```{r f_val_data_frame, echo=FALSE}
sim.max.f.print.path <- max(f_vals$path.sim.f) %>%
  format(digits = 2)
sim.max.f.print.reg <- max(f_vals$reg.sim.f) %>%
  format(digits = 2)
actual.f.path <- path.f.real %>%
  format(digits = 2)
actual.f.reg <- reg.f.real %>%
  format(digits = 2)
```

| f-value      | Simulated maximum        | Observed          |
|--------------|--------------------------|-------------------|
| by pathology | `r sim.max.f.print.path` | `r actual.f.path` |
| by region    | `r sim.max.f.print.reg`  | `r actual.f.reg`  |

# Monte Carlo Tukey Test

A Tukey test works by comparing means of all possible combinations of populations (in this case, regions or pathotypes) and then comparing to a studentized range distribution. I'm going to do exactly this, except that the studentized range distribution is replaced with the observed distribution of mean differences in shuffled data.

```{r}
# Let's make a function to calculate actual means and then simulated means
#tic()
n.tukey <- 1e4
zor_path_diffs <- monte_carlo_tukey(raw_path_zor, n.tukey)
zor_region_diffs <- monte_carlo_tukey(raw_region_zor, n.tukey)
#toc() # about 13 seconds on my laptop
```

# Results

## zor-orz results

```{r}
knitr::kable(zor_path_diffs)
```
### How to interpret this table

This is a table comparing differences in the mean gene number between each pair of groups. For instance, the top row is `Africa-Asia`, `mean.diff` indicates that the absolute value of the difference in the mean number of zor/orz genes between Africa and Asia is 0.091. `cutoff.diff`, the "cutoff" above which a difference would be statistically significant (p \< 0.05), is 0.286. 0.091 is not greater than 0.286, so there is no significant difference. Thus, the `sig.diff` entry is FALSE.

`Asia-North America`, does have a significant difference: `cutoff.diff` is 0.087, `mean.diff` is 0.183, so `sig.diff` is TRUE.

```{r}
knitr::kable(zor_region_diffs)
```
## tisB results

```{r}
path_tis <- readxl::read_xlsx("data/FINAL data for Steen after reviewer comments.xlsx", 
                            #sheet = "already analyzed tisB-istR gene",
                            sheet = 3,
                            range = "A1:E3") %>%
  rename(gene.count = Pathotype) %>%
  pivot_longer(-1, names_to = "category", values_to = "count") %>%
  group_by(category) %>%
  mutate(freq = count / sum(count, na.rm = TRUE))
raw_path_tis <- recreate_raw(path_tis)

# simulate f values under resampled data
path.tis.f.vec <- future_map_dbl(seq_along(1:n), 
                            shuf_calc_f, 
                            df=raw_path_tis, #nrow=nrow(raw_human_tis), 
                             .options = furrr_options(seed = 944)) # fun vehicle in which to not drive 55
path_tis_f <- data.frame(path.tis.sim.f = path.tis.f.vec)

# Identify true f value. To make it comparable, I'll use aov, even though it's just a t test at this point
m_path_tis <- lm(gene.count ~ category, data = raw_path_tis)
path.tis.real <- summary(aov(m_path_tis))[[1]][1,4] # 66, almost!

p_path_tis <- ggplot(path_tis_f, aes(x=path.tis.sim.f)) + 
  geom_histogram(bins = 100) + 
  geom_vline(xintercept = path.tis.real, color="red") + 
  ggtitle("tis data by pathology")
print(p_path_tis)
```
#### tis Tukey

```{r}
tis_path_diffs <- monte_carlo_tukey(raw_path_tis, n.tukey)
```


# Human vs non-human animal

Based on a reviewer request, we need to do the same test with humans vs non-human animals, for zor-orz and tis-istR.

Again, the first step is to recreate the raw data:

```{r tis_full_analysis}
human_tis <- readxl::read_xlsx("data/FINAL data for Steen after reviewer comments.xlsx", 
                            sheet = "to analyze based on reviewers c",
                            range = "A2:C4") %>%
  rename(gene.count = `gene copy number`) %>%
  pivot_longer(-1, names_to = "category", values_to = "count") %>%
  group_by(category) %>%
  mutate(freq = count / sum(count, na.rm = TRUE))

human_zor <- readxl::read_xlsx("data/FINAL data for Steen after reviewer comments.xlsx", 
                            sheet = "to analyze based on reviewers c",
                            range = "A10:C17") %>%
  rename(gene.count = `gene copy number`) %>%
  pivot_longer(-1, names_to = "category", values_to = "count") %>%
  group_by(category) %>%
  mutate(freq = count / sum(count, na.rm = TRUE))

raw_human_tis <- recreate_raw(human_tis) #%>%
raw_human_orz <- recreate_raw(path_zor)
```

Now we have to compare the actual f-values for the ANOVA to the distributions of simulated f-values. 

```{r simulate_human_f_values}
# Make up artificial f values for the human/nonhuman tis data
# Not even sure whether this is different, but it works after fixing some silly errors

# Iterate the shuffle-and-count-f function n times; place data in a vector
human.tis.f.vec <- future_map_dbl(seq_along(1:n), 
                            shuf_calc_f, 
                            df=raw_human_tis, #nrow=nrow(raw_human_tis), 
                             .options = furrr_options(seed = 55)) # a speed at which I can't drive
human.orz.f.vec <- future_map_dbl(seq_along(1:n), 
                             shuf_calc_f, 
                             df=path_zor, #nrow=nrow(raw_human_orz), 
                             .options = furrr_options(seed = 99991)) # allegedly the largest 5-digit prime number 
#toc() # Runs in about 14 seconds on 6 core macbook pro; pretty sweet

# put the simulated f values in a data frame
human_f_vals <- data.frame(human.tis.f = human.tis.f.vec,
                     human.orz.f = human.orz.f.vec)
```

Now calculate the actual f values:
```{r real_human_models}
human_tis_model <- lm(gene.count ~ category, data = raw_human_tis)
human.tis.real <-  summary(aov(human_tis_model))[[1]][1,4] # 171.1295
human_orz_model <- lm(gene.count ~ category, data = raw_human_orz)
human.orz.real <-  summary(aov(human_orz_model))[[1]][1,4] # 46.03
```

```{r}
p_human_tis <- ggplot(human_f_vals, aes(x=human.tis.f)) +
  geom_histogram(bins = 100) +
  geom_vline(xintercept = human.tis.real, color="red") +
  ggtitle("human-vs-nonhuman tis")
print(p_human_tis)
```


```{r}
p_human_orz <- ggplot(human_f_vals, aes(x=human.orz.f)) +
  geom_histogram(bins = 100) +
  geom_vline(xintercept = human.orz.real, color="red") +
  ggtitle("human-vs-nonhuman orz")
print(p_human_orz)
```

Looks like these are both highly significant, again! As before, we can't assign a p value because the observed f value is (way) more extreme than any observed f value in the simulations, but we can say that p < `r 1/n`.

  

